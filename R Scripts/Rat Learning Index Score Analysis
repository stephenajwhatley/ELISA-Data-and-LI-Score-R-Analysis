# Learning Index (LI) Score Analysis by Group
# Adapted from ELISA pipeline (excluding ELISA-specific elements such as Technical Outlier Removal, 4PL Fit, Concentration Interpolation)
# Author: [Whatley, S.A.J.]
# Date: [2025-08-10]

# 0. USER PARAMETERS
file  <- "LI-SampleData.xlsx"     # Excel file path
sheet <- 1                        # Sheet index containing LI data

# 1. Load packages
pkgs <- c("readxl", "dplyr", "tidyr", "ggplot2", "rstatix", "effsize", "effectsize", "TOSTER")
invisible(lapply(pkgs, function(p) {
  if (!requireNamespace(p, quietly = TRUE)) install.packages(p)
  library(p, character.only = TRUE)
}))

# 2. Modified Z-score function for outlier detection (final step)
calc_mod_z <- function(x) {
  med <- median(x, na.rm = TRUE)
  mad_val <- median(abs(x - med), na.rm = TRUE)
  if (mad_val < 1e-6) mad_val <- stats::mad(x, constant = 1.4826, na.rm = TRUE)
  0.6745 * (x - med) / mad_val
}

# 3. Read and clean data
smp_clean <- read_excel(file, sheet = sheet) %>%
  rename(
    sample_id = 1,
    group     = 2,
    li_score  = 3
  ) %>%
  mutate(group = factor(group, levels = c("Young", "Aged")))

# 4. Assumption testing
norm_tests <- smp_clean %>% group_by(group) %>% shapiro_test(li_score)
var_test  <- levene_test(li_score ~ group, data = smp_clean, center = "median")

  #Print Group Summaries
  group_summary <- smp_clean %>%
    group_by(group) %>%
    summarise(
      n      = n(),
      mean   = mean(li_score),
      sd     = sd(li_score),
      median = median(li_score),
      IQR    = IQR(li_score),
      min    = min(li_score),
      max    = max(li_score)
    )
  print(group_summary)
  
# 5. Group Testing
if (all(norm_tests$p > 0.05) && var_test$p > 0.05) {
  test_res  <- t_test(li_score ~ group, data = smp_clean, var.equal = TRUE)
  test_used <- "Student’s t-test"
  reason    <- "normality and homogeneity of variance satisfied"
} else if (all(norm_tests$p > 0.05) && var_test$p <= 0.05) {
  test_res  <- t_test(li_score ~ group, data = smp_clean, var.equal = FALSE)
  test_used <- "Welch’s t-test"
  reason    <- "Brown-Forsythe p ≤ 0.05 (heterogeneity of variance)"
} else {
  test_res  <- rstatix::wilcox_test(li_score ~ group, data = smp_clean)
  test_used <- "Mann–Whitney U"
  reason    <- "at least one group failed Shapiro-Wilk test for normality"
}

p_val <- test_res$p


# 6. Effect Size and Equivalence
should_run_equiv <- FALSE
if (test_used == "Mann–Whitney U") {
  es_df <- wilcox_effsize(smp_clean, li_score ~ group, conf.level = 0.95)
  g <- es_df$effsize[1]
  ci_low  <- es_df$conf.low[1]
  ci_high <- es_df$conf.high[1]
  magnitude <- ifelse(abs(g) < 0.1, "negligible",
                  ifelse(abs(g) < 0.3, "small",
                  ifelse(abs(g) < 0.5, "medium", "large")))
  should_run_equiv <- (magnitude == "negligible")
} else {
  # Compute Hedges' g directly from raw data
  es <- hedges_g(li_score ~ group, data = smp_clean, conf.level = 0.95)
  g        <- es$Hedges_g
  ci_low   <- es$CI_low
  ci_high  <- es$CI_high
  magnitude <- ifelse(abs(g) < 0.2, "negligible",
                  ifelse(abs(g) < 0.5, "small",
                  ifelse(abs(g) < 0.8, "medium", "large")))
  should_run_equiv <- (magnitude == "negligible")
}
# Ensure ci_low and ci_high exist for downstream reporting
# 7. Optional Equivalence Testing. Optional Equivalence Testing
if (should_run_equiv) {
  g1 <- levels(smp_clean$group)[1]
  g2 <- levels(smp_clean$group)[2]
  m1 <- mean(smp_clean$li_score[smp_clean$group == g1])
  m2 <- mean(smp_clean$li_score[smp_clean$group == g2])
  sd1 <- sd(smp_clean$li_score[smp_clean$group == g1])
  sd2 <- sd(smp_clean$li_score[smp_clean$group == g2])
  n1 <- sum(smp_clean$group == g1)
  n2 <- sum(smp_clean$group == g2)
  tost <- TOSTER::tsum_TOST(m1, sd1, n1, m2, sd2, n2,
                            low_eqbound = -0.2, high_eqbound = 0.2)
  print(tost)
}

# 8. Post-hoc Outlier Detection (Modified Z)
outliers <- smp_clean %>%
  group_by(group) %>%
  mutate(mod_z = calc_mod_z(li_score)) %>%
  filter(abs(mod_z) > 3.5)
print("Potential outliers by Modified Z (>3.5):")
print(outliers)

# 9. Boxplot
bp_stats <- ggplot_build(
  ggplot(smp_clean, aes(x = group, y = li_score)) +
    geom_boxplot(outlier.shape = NA)
)$data[[1]] %>%
  mutate(
    x_center  = (xmin + xmax) / 2,
    cap_width = (xmax - xmin) / 3
  )

# Add group factor for coloring
bp_stats$group <- factor(c("Young", "Aged"), levels = c("Young", "Aged"))

# Add group sample sizes
group_counts <- smp_clean %>% count(group)

# Format p-value string for annotation
p_label <- if (p_val < 0.001) {
  "italic(p) < 0.001"
} else if (p_val < 0.01) {
  sprintf("italic(p) == %.3f", p_val)
} else {
  sprintf("italic(p) == %.2f", p_val)
}

# Construct the boxplot with consistent y-axis scaling
bp <- ggplot(smp_clean, aes(x = group, y = li_score)) +
  geom_boxplot(
    outlier.shape = NA,
    width = 0.5,
    fill  = NA,
    color = c("#003380", "#FF6600"),
    size  = 0.6
  ) +
  geom_jitter(
    aes(color = group),
    width = 0.3,
    size  = 1.5,
    alpha = 0.7
  ) +
  scale_color_manual(values = c("Young" = "#003380", "Aged" = "#FF6600")) +
  scale_y_continuous(
    limits = c(100, 400),
    breaks = seq(100, 400, 50),
    expand = expansion(mult = c(0.02, 0.05))
  ) +
  geom_segment(data = bp_stats,
               aes(x = x_center - cap_width/2, xend = x_center + cap_width/2,
                   y = ymin, yend = ymin, color = group),
               size = 0.8) +
  geom_segment(data = bp_stats,
               aes(x = x_center - cap_width/2, xend = x_center + cap_width/2,
                   y = ymax, yend = ymax, color = group),
               size = 0.8) +
  stat_summary(
    fun = median,
    geom = "crossbar",
    width = 0.3,
    aes(color = group),
    size = 0.8
  ) +
  labs(
    y = "LI Score",
    x = "Age Group"
  ) +
  theme_classic(base_size = 14) +
  theme(
    legend.position    = "none",
    axis.title.y      = element_text(colour = "black", face = "bold", size = 14, margin = margin(r = 10)),
    axis.text.y       = element_text(colour = "black", size = 13),
    axis.title.x      = element_text(colour = "black", face = "bold", size = 14, margin = margin(t = 15)),
    axis.text.x       = element_text(colour = "black", size = 13)
  ) +
  geom_text(
    data = group_counts,
    aes(x = group, y = 105, label = paste0("n = ", n)),
    inherit.aes = FALSE,
    size = 4.5,
    fontface = "italic"
  ) +
  annotate("text",  
           x = 1.5, y = 390,
           label = p_label, parse = TRUE, 
           size = 5, hjust = 0.5
          )

print(bp)

# 10. Interpret p-value and output
interpret_result <- function(p){
  if(p<0.001) "Highly significant (p<0.001)"
  else if(p<0.01) "Very significant (p<0.01)"
  else if(p<0.05) "Significant (p<0.05)"
  else "Not significant (p≥0.05)"
}
qual <- interpret_result(p_val)

cat("=== Normality ==="); print(norm_tests)
cat("Interpretation: ", if(all(norm_tests$p>0.05)) "All normal" else "Non-normal groups", "\n\n")
cat("=== Variance ==="); print(var_test)
cat("Interpretation: ", if(var_test$p>0.05) "Homoscedastic" else "Heteroscedastic", "n\n")
cat("=== Test ===", test_used, " (", reason, ")\n\n")
cat("=== Result ===", qual, " (p =", round(p_val,4), ")\n\n")
# Dynamic Effect Size Reporting
cat("=== Effect Size ===",
    sprintf("Effect size g = %.3f (%s)", g, magnitude), "",
    sprintf("95%% CI = [%.3f, %.3f]", ci_low, ci_high), "")
